{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c35133e-ad13-48a5-9371-9625d668504b",
   "metadata": {},
   "source": [
    "# Multi-Agent Review Generation for Scientific Papers\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Peer-review of scientific papers is a central part of decision making process in academic journals. A research paper submitted to the journal is typically assigned 2-3 reviewers with an expertise in corresponding fields, who are requested to provide detailed responses regarding originality and impact of research study, its potential flaws and areas for improvement. Based on results of peer review, editor makes decision either to publish paper in a journal, reject it, or request authors to do additional work and improve / revise the paper.\n",
    "\n",
    "Results of peer review process can be highly subjective and susceptible to bias. To eliminate bias, some journals have introduced double-blind mode, when author identity is not revealed to reviewers. Studies have shown that under double-blind peer-review, acceptance rate is increased for female authors and decreases for famous authors and authors from high-prestige institutions [1-8]. However, double blind peer-review cannot completelty eliminate human factor and guarantee anonymization of author identity in e.g. small research areas. Furthermore, an increasing number of research works today are being made available open access before publication, in a preprint form.\n",
    "\n",
    "In addition to this, the number of subsmissions to academic journals has been continously growing, making in harder for the journal to recruit enough professional reviewers to handle that volume [9].\n",
    "\n",
    "Automatization of peer review process can be a potential remedy to these problems. Although machine learning and natural language processing methods today are used by academic publishers for automatic pre-screening of submissions [10], the area is still in its infancy and major part of the review process remains non-automated. Recently, large language models have revolutionized the field of AI; neural networks based on transformer architecture provide a much more nuanced understanding of human language and a able to memorize a large amount of knowledge while training.\n",
    "\n",
    "### Approach & related work\n",
    "\n",
    "The ability of large language models such as ChatGPT to generate reviews for academic papers has been explored in a number of studies [11-16]. One of the recent developments is MARG, a system for multi-agent review generation [16]. The rationale for this system was based on limitation of early version of GPT-4. The size of the context window was limited to 8192 tokens, that was not enough to process a whole research paper. MARG uses multiple AI agents to process different chunks of the paper, after that reviews generated by individual agents are summarized by expert and main agents. The system was shown to increase the amount of usable or actionable feedback instead of general comments in reviews produced with GPT-4.\n",
    "\n",
    "Since the MARG system was introduced, large language models became more advanced; the latest version of GPT now supports up to 128K tokens in the context window, eliminating the problem initially solved by system [17]. Recently, Titan architecture for neural networks was introfuced by Google, thar enabled even larger context size up to 2M [18]. Still, multi-agent review generation can have advantages, as it enables different AI agents to focus on different sections and aspects of the paper. Furthermore, MARG uses traditional chat completion API, while OpenAI has recently introduced Assistants API that makes development of multi agent systems easier [19].\n",
    "\n",
    "In this work, multi-agent review generation system for scientific papers will be developed, that will be based on approach introduced by MARG, but using a new API and implementing a number of improvements that are intended to make multi-agent systems more accessible for research and experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb6c10-551c-4402-b0c5-ac349535f84d",
   "metadata": {},
   "source": [
    "### Libraries & dependencies\n",
    "\n",
    "This notebook uses some non-standard libraries that must be installed on the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073e67a-e84e-4bc1-9dda-bc09d14e3338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install names                # name generation for agents\n",
    "! pip install OpenAI tiktoken      # interaction with GPT-4o model\n",
    "! pip install markdown ipywidgets  # formatting outputs\n",
    "                                   # loading and processing PDF files\n",
    "! pip install ipyfilechooser grobid-client-python grobid2json lxml BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0acf3f-9d9c-4b01-ba0e-dfc03cdf4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import base64\n",
    "import random\n",
    "import pandas\n",
    "import tiktoken\n",
    "import ipywidgets\n",
    "\n",
    "from glob import glob\n",
    "from openai import OpenAI\n",
    "from bs4 import BeautifulSoup\n",
    "from markdown import markdown\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from names import get_full_name\n",
    "from ipyfilechooser import FileChooser\n",
    "from grobid2json import convert_xml_to_json\n",
    "from grobid_client.grobid_client import GrobidClient\n",
    "from IPython.display import clear_output, display, HTML\n",
    "from ipywidgets import HBox, Image, IntProgress, Layout\n",
    "\n",
    "tiktoken.encoding_for_model(\"gpt-4o\") ; # pre-load model data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9637216-b154-4032-a81d-42ac3b53af35",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "To run code in this notebook smoothly, **Tier 2** OpenAI API key is recommended. The address of running [GrobID instance](https://grobid.readthedocs.io/en/latest/Run-Grobid/) is required to extract text from PDF files (the service can be installed locally with Docker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f00c4516-f91d-4763-82d0-3c07057dc3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "GROBID_SERVER  = \"http://127.0.0.1:8070\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9291181-1b95-4f62-9651-2bf4c051a7b4",
   "metadata": {},
   "source": [
    "### PDF preprocessing\n",
    "\n",
    "A research paper submitted for review will be split into sections, and every agent will be assigned one or more sections of the paper to analyze (short sections will be concatenated together). Furthermore, each agent will have information about title and abstact of the paper.\n",
    "\n",
    "To do this task, I will use GROBID -- an advanced service for processing PDF research articles that can extract different sections of the paper. The following class imlpements pre-processing functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b94c126e-0e89-4e21-8243-5194fe6fe2ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n"
     ]
    }
   ],
   "source": [
    "grobid = GrobidClient(grobid_server = GROBID_SERVER) # connect to GROBID service\n",
    "\n",
    "class Paper:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = grobid\n",
    "        self.folder = 'data/papers'  # cache for processed PDF\n",
    "        self.tokens = None           # estimate n of tokens per chunk\n",
    "        \n",
    "        # properties to keep structured text from processed PDF\n",
    "        self.title    = ''\n",
    "        self.abstract = ''\n",
    "        self.sections = {}\n",
    "        self.chunks   = []\n",
    "\n",
    "        self.filename = ''\n",
    "\n",
    "    # take path to PDF file and convert to structured JSON with GROBID\n",
    "    def json(self, pdf):\n",
    "        data = self.folder\n",
    "        pdfi = pdf.split('/')[-1].rsplit('.', 1)[0]\n",
    "        xml = f'{data}/{pdfi}.grobid.tei.xml'\n",
    "\n",
    "        # convert paper to XML form using GROBID service\n",
    "        # / take XML file from cache if available\n",
    "        if not os.path.exists(xml):\n",
    "            print('processing PDF file...', end = ' ')\n",
    "            try:\n",
    "                shutil.copyfile(pdf, f'{data}/{pdfi}.pdf')\n",
    "            except shutil.SameFileError:\n",
    "                pass\n",
    "            self.client.process('processFulltextDocument', data, output = data)\n",
    "            print('done.')\n",
    "\n",
    "        # convert XML to JSON format for easier processing\n",
    "        xml  = BeautifulSoup(open(xml, 'rb').read(), 'xml')\n",
    "        jres = convert_xml_to_json(xml, pdfi, \"\").as_json()\n",
    "\n",
    "        self.filename = pdfi\n",
    "        return jres\n",
    "\n",
    "    \n",
    "    # parse PDF file and extract title, abstact and sections\n",
    "    def parse(self, pdf):\n",
    "        paper = self.json(pdf) # parse PDF to JSON\n",
    "        self.sections = {}     # extract sections\n",
    "        for chunk in paper['body_text']:\n",
    "            sect, text = chunk['section'], chunk['text']\n",
    "            if sect not in self.sections:\n",
    "                self.sections[sect] = ''\n",
    "            self.sections[sect] += \"\\n\" + text\n",
    "            \n",
    "        self.title    = paper['metadata']['title']\n",
    "        self.abstract = paper['abstract'][0]['text']\n",
    "\n",
    "    # split PDF article to chunks of text of max token size\n",
    "    # cut off all text after stop section (conclusion by default)\n",
    "    def process(self, pdf, stop = 'conclusion', maxt = 1024, model = 'gpt-4o'):\n",
    "        self.parse(pdf) # extract article text split by sections\n",
    "        if self.tokens is None: # get tokenizer for model\n",
    "            # to estimate number of tokens in each chunk\n",
    "            self.tokens = tiktoken.encoding_for_model(model)\n",
    "\n",
    "        chunks, i = [], 0\n",
    "        for sect, text in self.sections.items():\n",
    "            if stop is not None:\n",
    "                if stop in sect.lower(): break\n",
    "\n",
    "            # append section to current chunk\n",
    "            if len(chunks) == i: chunks.append('')\n",
    "            chunks[i] += f\"\\n\\n[{sect}]\\n\\n{text.strip()}\"\n",
    "\n",
    "            # append new chunk if current is large enough\n",
    "            tokens = self.tokens.encode(chunks[i])\n",
    "            if len(tokens) > maxt: i += 1\n",
    "\n",
    "        self.chunks = chunks\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6405e3d-5113-4a17-b96e-3c677cf6b1be",
   "metadata": {},
   "source": [
    "I will choose research paper and process it using the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f38a7-8928-4704-b092-ca63db7bb696",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pdf = FileChooser()\n",
    "pdf.title = 'Select PDF article for review: '\n",
    "pdf.filter_pattern = '*.pdf'\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db4808-920f-4520-a8b9-df488cdcd925",
   "metadata": {},
   "source": [
    "Process the article PDF (if remote GROBID server is used, text extraction can take a minute or two) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad00bab6-6263-4f03-9499-bec93f42380c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attention Is All You Need\n",
      "\n",
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. * Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.\n",
      "\n",
      "Introduction\n",
      "Background\n",
      "Model Architecture\n",
      "Encoder and Decoder Stacks\n",
      "Attention\n",
      "Scaled Dot-Product Attention\n",
      "Multi-Head Attention\n",
      "Applications of Attention in our Model\n",
      "Position-wise Feed-Forward Networks\n",
      "Embeddings and Softmax\n",
      "Positional Encoding\n",
      "Why Self-Attention\n",
      "Training\n",
      "Training Data and Batching\n",
      "Hardware and Schedule\n",
      "Optimizer\n",
      "Regularization\n",
      "Label Smoothing\n",
      "Machine Translation\n",
      "Model Variations\n",
      "English Constituency Parsing\n",
      "Conclusion\n",
      "-----------------------------------------\n",
      "Input-Input Layer5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paper  = Paper()\n",
    "chunks = paper.process(pdf.selected)\n",
    "\n",
    "# preview the processed PDF file\n",
    "print(f'\\n{paper.title}\\n\\n{paper.abstract}\\n')\n",
    "\n",
    "for i, section in enumerate(paper.sections.keys()):\n",
    "    print(section)\n",
    "    if 'conclusion' in section.lower() and i + 1 < len(paper.sections):\n",
    "        print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcaed7cd-b2e5-4f97-834b-84e0b3d8542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of chunks: {len(chunks)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d173b5cb-4213-4cea-ac6e-9c32844bf1ab",
   "metadata": {},
   "source": [
    "To review this paper, 7 agents will be run (five reviewers for every chunk, one expert and one editor that will coordinate the whole process)\n",
    "\n",
    "### Multi-agent framework\n",
    "\n",
    "Let's start by initializing client for OpenAI API, and defining a generic class for OpenAI-based agent. The class will automatially generate a random name for AI agent if it was not provided, and assign a profile picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f9a34b-1e79-4eb7-9b05-452ce69734c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, name = '',\n",
    "                     gender = '',\n",
    "                     avatar = '',\n",
    "                       role = '',\n",
    "                      model = 'gpt-4o',\n",
    "                    context = None # messages to initialize chat\n",
    "                ):\n",
    "\n",
    "        self.gender = gender if gender else random.choice(['male', 'female'])\n",
    "        self.name = name if name else get_full_name(gender = self.gender)\n",
    "        self.avatar = avatar if avatar else photosource.take(self.gender)\n",
    "        self.role = role\n",
    "\n",
    "        # initialize OpenAI assistant, communication thread and context\n",
    "        self.agent = client.beta.assistants.create(\n",
    "            name = self.name, instructions = '', model = model)\n",
    "        self.thread = client.beta.threads.create()\n",
    "        basic = f\"Your name is {self.name}.\"\n",
    "        if self.role: basic += f' You are {self.role.lower()}'\n",
    "        if context is None: context = []\n",
    "        context.insert(0, basic)\n",
    "        self.context(context)\n",
    "        \n",
    "        self.message  = None  # most recent prompt\n",
    "        self.response = None  # most recent response\n",
    "        self.running  = None  # for asynchronous queries\n",
    "\n",
    "    # push messages that will be used as context for answer\n",
    "    def context(self, messages, role = \"user\"):\n",
    "        for message in messages:\n",
    "            client.beta.threads.messages.create(\n",
    "                    thread_id = self.thread.id, role = role, content = message)\n",
    "    \n",
    "    # retrieve most recent message in chat (e.g. answer from the model)\n",
    "    def answer(self):\n",
    "        messages = client.beta.threads.messages.list( thread_id = self.thread.id )\n",
    "        if messages.data:\n",
    "            self.response = messages.data[0].content[0].text.value.strip()\n",
    "        return self.response\n",
    "\n",
    "    # send message to the model and get response\n",
    "    def prompt(self, message):\n",
    "        self.message = message\n",
    "        client.beta.threads.runs.create_and_poll(\n",
    "            thread_id    = self.thread.id, \n",
    "            assistant_id = self.agent.id,\n",
    "            instructions = self.message)\n",
    "        return self.answer()\n",
    "\n",
    "    # for asynchronous answering, check for response\n",
    "    def complete(self):\n",
    "        if not self.running: return None\n",
    "        # check status of background query\n",
    "        self.running = client.beta.threads.runs.retrieve(\n",
    "                           thread_id = self.thread.id,\n",
    "                           run_id    = self.running.id)\n",
    "        # repeat the query in case of error\n",
    "        if self.running.status == \"failed\":\n",
    "            time.sleep(1)\n",
    "            self.queue()\n",
    "        if self.running.status == \"completed\":\n",
    "            self.running = None\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # query the model in background\n",
    "    def queue(self, message = None):\n",
    "        if message: self.message = message\n",
    "        self.running = client.beta.threads.runs.create(\n",
    "                           thread_id    = self.thread.id, \n",
    "                           assistant_id = self.agent.id,\n",
    "                           instructions = self.message)\n",
    "\n",
    "    # display information about the agent\n",
    "    def _ipython_display_(self):\n",
    "        display(HTML(f'''<div style = \"text-align:center;padding:18px;display:flex;align-items:center\">\n",
    "                    <img src = \"{self.avatar}\"\n",
    "                       align = \"middle\"\n",
    "                       style = \"width: 96px; border-radius: 12px;margin-right: 18px\">\n",
    "                    <div><b style = \"font-size: 18px\">\n",
    "                        {self.name}</b><br>\n",
    "                        {self.role}</div></div>'''))\n",
    "\n",
    "\n",
    "# auxiliary class for issuing random profile pictures\n",
    "class PhotoSource:\n",
    "\n",
    "    def __init__(self): self.reset()\n",
    "    def    reset(self): self.avatars = {gender: glob(f'data/avatars/{gender}/*') for gender in ['male', 'female']}\n",
    "    \n",
    "    def take(self, gender):\n",
    "        picture = random.choice(self.avatars[gender])\n",
    "        if picture:\n",
    "            self.avatars[gender].remove(picture)\n",
    "            if len(self.avatars[gender]) == 0:\n",
    "                self.reset()\n",
    "        return picture if picture else ''\n",
    "\n",
    "photosource = PhotoSource()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26bc1f4-2a27-48b2-a8f6-9e32e18adedb",
   "metadata": {},
   "source": [
    "Test class by creating a simple agent and asking a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6e45dba-e9fd-4103-a3b4-fc8f929ec1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style = \"text-align:center;padding:18px;display:flex;align-items:center\">\n",
       "                    <img src = \"data/avatars/female/teams_4.png\"\n",
       "                       align = \"middle\"\n",
       "                       style = \"width: 96px; border-radius: 12px;margin-right: 18px\">\n",
       "                    <div><b style = \"font-size: 18px\">\n",
       "                        Donna Gaydosh</b><br>\n",
       "                        Phd student</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "student = Agent(role = \"Phd student\")\n",
    "student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0133cc3b-b3a4-40ff-ad9d-be2c5c8dc3bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As Donna Gaydosh, a PhD student, my typical day likely revolves around a combination of research, coursework, and academic activities. Here's what my day might generally look like:\n",
      "\n",
      "### Morning\n",
      "- **6:30 AM**: Wake up and have breakfast. This is a good time to catch up on news or read articles related to my field of study.\n",
      "- **7:30 AM**: Head to the university, either by walking, biking, or public transit, depending on the distance.\n",
      "- **8:00 AM**: Start the day with lab work or begin my study session in a quiet spot at the library. This block of time is dedicated to focused work without interruptions.\n",
      "\n",
      "### Midday\n",
      "- **11:30 AM**: Attend a lecture or a seminar related to my coursework or research interests.\n",
      "- **1:00 PM**: Lunch break. Sometimes, I meet with peers or colleagues to discuss ongoing projects or just to socialize.\n",
      "- **2:00 PM**: Dedicate time to writing and reviewing my thesis or any papers I am working on. This includes data analysis and hypothesis testing.\n",
      "\n",
      "### Afternoon\n",
      "- **3:30 PM**: Attend meetings with my advisor or join a study group. This is also a common time for departmental events or workshops for skill development.\n",
      "- **5:00 PM**: Continue with lab work if required, especially if experiments need monitoring, or work on any teaching assistant duties if applicable.\n",
      "\n",
      "### Evening\n",
      "- **6:30 PM**: Head home or to a gym for a workout session to stay healthy and destress after a focused day.\n",
      "- **7:30 PM**: Dinner and some relaxation time, maybe watching a show or reading a book unrelated to my studies.\n",
      "- **8:30 PM**: Final check of emails and to-do lists for the next day. If necessary, spend some additional time on tasks that need urgent attention.\n",
      "- **10:00 PM**: Wind down with some relaxing activities, such as meditation or journaling, ensuring a good night’s rest.\n",
      "\n",
      "This routine is subject to variations depending on deadlines, conferences, or other academic commitments. During the semester, the schedule might include more classes, while periods leading to deadlines or exams could see increased workload. Balancing personal time and work is important, so I aim to include breaks and downtime within my schedule.\n"
     ]
    }
   ],
   "source": [
    "print(student.prompt(\"What does your typical day look like?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ea24d-0af5-4029-b79d-adb540f0685a",
   "metadata": {},
   "source": [
    "The answer took quite a time to generate. To avoid long waiting, let's extend the class by adding support for streaming, and also apply some formatting to the output so it will be easier to read. I will define a separate class *View* that will handle display of output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bbad794-1733-437b-8d7f-11b66390f42f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class View:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.box = None\n",
    "        self.author = None\n",
    "        self.answer = None\n",
    "    \n",
    "    # this method will be invoked by agent on receiving\n",
    "    # new tokens and once more when full answer in generated\n",
    "    def update(self, author, text, complete = None):\n",
    "\n",
    "        # some additional preprocessing depending on type of agent\n",
    "        text = author.prepare(text)\n",
    "        # answers from LLMs are formatted in markdown\n",
    "        text = markdown(text).replace('<h3>', '<h3 style = \"font-size: 14px\">')\n",
    "\n",
    "        # format and display the answer\n",
    "        if not self.answer: self.answer = ipywidgets.HTML()\n",
    "        self.answer.value = f\"\"\"<div style = \"border: solid 2px #ccc;\n",
    "                                     border-radius: 18px;\n",
    "                                     font-size: 12px;\n",
    "                                     line-height: 16px;\n",
    "                                     font-family: Courier;\n",
    "                                     max-width: 640px;\n",
    "                                     padding: 12px\">\n",
    "                                     {text}\n",
    "                                </div>\"\"\"\n",
    "\n",
    "        # display full reply box with author name and picture\n",
    "        if not self.box:\n",
    "            self.author = f\"\"\"<div style = \"padding: 0 12px 0 12px; \n",
    "                                         text-align: center\">\n",
    "                        <img src = \"{author.avatar}\"\n",
    "                           style = \"border-radius : 12px;\n",
    "                                            width : 96px\">\n",
    "                        <p style = \"text-align    : center\">\n",
    "                        <b style = \"font-size     : 14px;\n",
    "                                    font-weight   : bold;\">\n",
    "                                    {author.name}</b><br>\n",
    "                                    {author.role}</p>\n",
    "                        </div>\"\"\"\n",
    "            \n",
    "            self.author = widget(HTML(self.author))\n",
    "\n",
    "            columns = [self.author, self.answer]\n",
    "            if author.position == 'right':\n",
    "                columns.reverse()\n",
    "            self.box = HBox(columns)\n",
    "            \n",
    "            display(self.box)\n",
    "\n",
    "\n",
    "class NiceAgent(Agent):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position = 'left'\n",
    "    \n",
    "    # a stub method to apply additional processing\n",
    "    # before returning answer to the user\n",
    "    def prepare(self, response):\n",
    "        return response\n",
    "    \n",
    "    def stream(self, message, view = None):\n",
    "        if not view: view = View()\n",
    "\n",
    "        self.message = message\n",
    "        response = ''\n",
    "\n",
    "        # invoke API method for token streaming\n",
    "        with client.beta.threads.runs.stream(\n",
    "            thread_id    = self.thread.id,\n",
    "            assistant_id = self.agent.id,\n",
    "            instructions = self.message) as stream:\n",
    "                for text in stream.text_deltas:\n",
    "                    # append new tokens and\n",
    "                    # display updated answer\n",
    "                    response += text\n",
    "                    view.update(self, response)\n",
    "        \n",
    "        # finalize the answer when it's complete\n",
    "        view.update(self, response, complete = True)\n",
    "        self.response = response\n",
    "        return response\n",
    "\n",
    "# auxiliary function for creating\n",
    "# re-usable element representations\n",
    "def widget(element):\n",
    "    result = ipywidgets.Output()\n",
    "    with result: display(element)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86a64c-5b36-4e24-9961-afb228cdb22f",
   "metadata": {},
   "source": [
    "Let's check how answering is now improved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "188c8785-a514-4846-9135-2658e33bc2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde512e156c84c71b078cd7f17749dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poet = NiceAgent(name = \"William Shakespeare\", role = \"Poet\", gender = \"male\")\n",
    "poet.stream(\"To be or not to be? Answer in a poem.\") ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc877b-7a04-4119-ad1c-ac63d179772f",
   "metadata": {},
   "source": [
    "### Multi-agent review system\n",
    "\n",
    "Now we can proceed to building a multi-agent system for peer review and define a generic class that will include everyone involved in the process - editor, expert and reviewers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e667f187-6a12-4886-9357-e4b0e27df6a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ReviewAgent(NiceAgent):\n",
    "    \n",
    "    def __init__(self, role):\n",
    "        # system prompt will be loaded at startup from .txt file\n",
    "        self.system = open(f'data/prompts/{role.lower()}.txt').read()\n",
    "        super().__init__(role = role)\n",
    "\n",
    "    \n",
    "    def invite(self, editor):\n",
    "        # when agent joins a group, it will get an initial prompt\n",
    "        # with the name of the group leader (editor)\n",
    "        self.context([self.system.replace('{editor}', editor.name)])\n",
    "\n",
    "    \n",
    "    # the group will use a specific protocol for communication\n",
    "    # so responses must be cleared from protocol terms before viewing\n",
    "    \n",
    "    def prepare(self, response):\n",
    "        prefix, s = 'SEND MESSAGE', ' *:'\n",
    "        messages = response.split(prefix)\n",
    "        messages = [f.strip(s).strip() for f in messages if f.strip(s) != '']\n",
    "        response = '\\n\\n'.join(messages)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19643e87-6f4e-4ccd-b2da-cba44fc00c93",
   "metadata": {},
   "source": [
    "Now we can define classes for each type of agent. Editor class will be the most complex of all, as it will handle hiring other members of the team:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ae12cce-4177-4a3f-94a8-40d1f241ca5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Editor(ReviewAgent):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(role = 'Editor')\n",
    "        self.context([self.system]) # apply initial prompt\n",
    "        self.team = []              # list of all agents (reviewers) in the group\n",
    "        self.discussion = []        # list of responses from all reviewers\n",
    "        self.verbose = True         # if True live discussion will be displayed\n",
    "\n",
    "    # save new message that was received from other agent, or Editor's own\n",
    "    def save(self, member, message):\n",
    "        self.discussion.append((datetime.now(),\n",
    "                                member.name,\n",
    "                                member.role,\n",
    "                                member.avatar,\n",
    "                                message))\n",
    "\n",
    "    # add reviewer / expert to the group\n",
    "    def invite(self, member):\n",
    "        \n",
    "        # send the bame of the Editor to new group member\n",
    "        member.invite(self)\n",
    "        \n",
    "        self.team.append(member)\n",
    "        if member.role == 'Expert':\n",
    "            self.expert = member\n",
    "        return member\n",
    "\n",
    "    # send Editor's message to all agents in the group\n",
    "    def broadcast(self, message):\n",
    "        # display progress bar if not in silent mode\n",
    "        # (sending through API will introduce small delays)\n",
    "        if self.verbose:\n",
    "            sending = IntProgress(value = 0, min = 0, max = len(self.team),\n",
    "                            description = 'Broadcasting message:',\n",
    "                                  style = {'bar_color': 'darkcyan',\n",
    "                                           'description_width': 'initial'},\n",
    "                                 layout = {'margin': '4px 0 12px 188px'})\n",
    "            display(sending)\n",
    "\n",
    "        # send message to every member in random order\n",
    "        random.shuffle(self.team)\n",
    "        for member in self.team:\n",
    "            member.context([f\"From: {self.role} {self.name}\\n\\n{message}\"])\n",
    "            member.queue(f\"You received new message (above) from {self.role} {self.name}. {self.role} is waiting for your reply.\")\n",
    "            if self.verbose: sending.value += 1\n",
    "\n",
    "    \n",
    "    # collect answers from all members\n",
    "    def collect(self):\n",
    "        answers = []\n",
    "        for member in self.team:\n",
    "\n",
    "            # skip the member if Editor did not ask anything\n",
    "            if member.running:\n",
    "                while not member.complete():\n",
    "                    time.sleep(1)\n",
    "                response = member.answer()\n",
    "                if 'will stand by for further instructions' not in response:\n",
    "                    answers.append(f\"From: {member.role} {member.name}\\n\\n{response}\")\n",
    "                    self.save(member, response)\n",
    "                    if self.verbose:\n",
    "                        View().update(member, response, True)\n",
    "        return answers\n",
    "\n",
    "\n",
    "    def submit(self, paper, limit = 128):\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Thank you for submitting your paper!\\n\\033[1m{paper.title}\\033[0m\")\n",
    "        \n",
    "        self.invite(Expert())\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"\\nYour paper will be evaluated by an expert:\")\n",
    "            display(self.expert)\n",
    "        \n",
    "            print('Recruiting reviewers...\\n')\n",
    "            tab = panel()\n",
    "            \n",
    "        for chunk in paper.chunks:\n",
    "            \n",
    "            reviewer = self.invite(Reviewer())\n",
    "            reviewer.assign(paper, chunk)\n",
    "            \n",
    "            if self.verbose: tab.put(reviewer)\n",
    "        \n",
    "        task = open(f'data/prompts/editor.task.txt').read()\n",
    "        task = task.replace(\"{expert}\", self.expert.name)\n",
    "\n",
    "        prompt = task\n",
    "\n",
    "        prompt += f'\\n\\nThe title of the research paper is: {paper.title}\\n\\n'\n",
    "        prompt += f'Abstract: {paper.abstract}'\n",
    "        \n",
    "        self.discussion = []\n",
    "        askme = self.stream if self.verbose else self.prompt\n",
    "        while prompt and not ('READY' in askme(prompt) and self.discussion):\n",
    "            prompt = ''\n",
    "\n",
    "            self.broadcast(self.response)\n",
    "            self.save(self, self.response)\n",
    "            \n",
    "            answers = self.collect()\n",
    "            if answers:\n",
    "                answers.insert(0, \"You have received following responses from the group members:\")\n",
    "                self.context(answers)\n",
    "                prompt  = \"Please carefully read the responses. If needed, ask for additional clarifications, and provide information requested by other agents. Then proceed with the task according to the plan.\"\n",
    "\n",
    "            if limit != None and len(self.discussion) > limit: break\n",
    "\n",
    "        self.save(self, self.response)\n",
    "\n",
    "\n",
    "# auxiliary class to display teams\n",
    "class panel():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.b = HBox([], layout = Layout(flex_flow = 'row wrap'))\n",
    "        display(self.b)\n",
    "        \n",
    "    def put(self, o):\n",
    "        self.b.children = tuple(list(self.b.children) + [widget(o)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd319b-7288-4030-9daf-25f4d3678e2d",
   "metadata": {},
   "source": [
    "Initialize editor agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70e744f0-b8e7-432b-b056-4feab9cf11f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style = \"text-align:center;padding:18px;display:flex;align-items:center\">\n",
       "                    <img src = \"data/avatars/female/vibrent_15.png\"\n",
       "                       align = \"middle\"\n",
       "                       style = \"width: 96px; border-radius: 12px;margin-right: 18px\">\n",
       "                    <div><b style = \"font-size: 18px\">\n",
       "                        Betty Watson</b><br>\n",
       "                        Editor</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "editor = Editor()\n",
    "editor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793ade3f-1865-481d-b1fe-b92c7716a344",
   "metadata": {},
   "source": [
    "Reviewer and Expert classes will require less code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c4e6aad-146a-42f7-a4cf-02efcb12ff41",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class Expert(ReviewAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(role = 'Expert')\n",
    "\n",
    "class Reviewer(ReviewAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(role = 'Reviewer')\n",
    "        self.position = 'right'\n",
    "\n",
    "    def assign(self, paper, chunk):\n",
    "        self.context([f\"\"\"\n",
    "        Title: {paper.title}\n",
    "        Abstract: {paper.abstract}\n",
    "        \n",
    "        Your paper chunk is shown below:\n",
    "            --- START PAPER CHUNK ---\n",
    "            { chunk }\n",
    "            --- END PAPER CHUNK ---\"\"\"])\n",
    "\n",
    "    def _ipython_display_(self):\n",
    "        display(HTML(f'''<div style = \"text-align: center; width: 64px\">\n",
    "                         <img style = \"width: 100%; border-radius: 4px\" src = \"{self.avatar}\">\n",
    "                           <p style = \"text-align: center\">\n",
    "                           <b style = \"font-size: 14px;\n",
    "                                    font-weight: bold;\">\n",
    "                                    {self.name}</b></p></div>'''))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647275d-8d0a-44e1-ac59-535e5b0543e6",
   "metadata": {},
   "source": [
    "We can now submit our paper for automated review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d33c0259-736c-446b-8277-73241457218e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for submitting your paper!\n",
      "\u001b[1mAttention Is All You Need\u001b[0m\n",
      "\n",
      "Your paper will be evaluated by an expert:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style = \"text-align:center;padding:18px;display:flex;align-items:center\">\n",
       "                    <img src = \"data/avatars/male/upstream_16.png\"\n",
       "                       align = \"middle\"\n",
       "                       style = \"width: 96px; border-radius: 12px;margin-right: 18px\">\n",
       "                    <div><b style = \"font-size: 18px\">\n",
       "                        Alex Heming</b><br>\n",
       "                        Expert</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recruiting reviewers...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e51248e2de41bd8a003cd710ceaec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(flex_flow='row wrap'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166097c20e1740aab766473e50282424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ad643a92964f92818b52bc258aefc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Broadcasting message:', layout=Layout(margin='4px 0 12px 188px'), max=6, sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd07e6255bd640a9a2152c4f70fb6f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64bf800ee6244d3b926aaac67ddd514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72218929a34e4513b391504830c15bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3094775279449e19a8da56e48791511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Broadcasting message:', layout=Layout(margin='4px 0 12px 188px'), max=6, sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9261fd83f624567af2c8ff553c60c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5faa39cb002e4719b49aa2e5e5c59138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a36cac906e84d7ab7c2bb38ef1a3024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eee87c07365411cbb4b74d689bf0285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Broadcasting message:', layout=Layout(margin='4px 0 12px 188px'), max=6, sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2266870037cd4dda96dc9df920f2c987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7dcdf829634d5bbf0644f022188fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d09962d0cc441c0b9827a48a72a799a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9236c329f145c390ca9d1969edb50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07883ffca9ab47ca8fb256aad3f062c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b76badd9a53437bb774c83c65194db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Broadcasting message:', layout=Layout(margin='4px 0 12px 188px'), max=6, sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99961e76a3f4946a86cdec9b358a568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5605d361c1044a7f8528a7592536fabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e9693d8a8f48ebae76c5a12b5877ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308fe0ebe9624fbba473b4aa799f879d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Broadcasting message:', layout=Layout(margin='4px 0 12px 188px'), max=6, sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cedc1885234d50864752ba80848caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25410801efb9438e9eea02c9d7b45d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41193412d59b4b77a3c68af48128dd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e10c49fb78941f492d3a95d1fe8e43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4f444c7bd54edb96891b15c9dbc345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c1fea2b3a4486e994673b8bff40fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Broadcasting message:', layout=Layout(margin='4px 0 12px 188px'), max=6, sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1225a88d05e54165bf3c7771510a4ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0df2cce20fa4fbf8505e339ed3d1d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c180e56b11864281bacedf677c48685c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efee0c4869254cc6b9cf3a0886e9a565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div style = \"border: solid 2px #ccc;\\n                                     border-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3589edee7a4ec88992808df0d25e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), HTML(value='<div style = \"border: solid 2px #ccc;\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "editor.submit(paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9e9744-5cb7-49f3-9766-4db053ccdfc3",
   "metadata": {},
   "source": [
    "### Reporting\n",
    "\n",
    "The following class will be helpful to save output to HTML or JSON file for later analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e010c72b-029c-42c1-a0af-de2ae2831c3d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Report:\n",
    "\n",
    "    def __init__(self, editor, paper):\n",
    "        self.editor = editor\n",
    "        self.paper  = paper\n",
    "\n",
    "    def json(self):\n",
    "\n",
    "        def date2json(dt): \n",
    "            return dt.isoformat() if isinstance(dt, datetime) else None\n",
    "        \n",
    "        report = {'title'      : self.paper.title,\n",
    "                  'abstract'   : self.paper.abstract,\n",
    "                  'sections'   : self.paper.sections,\n",
    "                  'filename'   : self.paper.filename,\n",
    "                  \n",
    "                  'discussion' : self.editor.discussion}\n",
    "        \n",
    "        jo = f'data/results/{paper.filename}.json'\n",
    "        open(jo, 'w').write(json.dumps(report, default = date2json))\n",
    "    \n",
    "    def html(self):\n",
    "        \n",
    "        htmlres = ''\n",
    "        for record in self.editor.discussion:\n",
    "            tstamp, name, role, avatar, comment = record\n",
    "            comment = self.editor.prepare(comment)\n",
    "            comment = markdown(comment).replace('<h3>', '<h3 style = \"font-size: 14px\">')\n",
    "            comment = f'<div class = \"comment\">{comment}</div>'\n",
    "            image64 = base64.b64encode(open(avatar, 'rb').read()).decode()\n",
    "            block   = f\"\"\"<div class = \"author\">\n",
    "                                <img src = \"data:image/jpeg;base64,{image64}\">\n",
    "                                <div class = \"name\">{name}</div>\n",
    "                                <div class = \"role\">{role}</div>\n",
    "                                <div class = \"time\">{tstamp}</div>\n",
    "                          </div>\"\"\"\n",
    "            if role in ['Editor', 'Expert']:\n",
    "                  block  = comment + block\n",
    "            else: block += comment\n",
    "            htmlres += f'<div class = \"reply\">{block}</div>'\n",
    "        \n",
    "        html = f\"\"\"\n",
    "        <html>\n",
    "            <head>\n",
    "                <title>Review for: {self.paper.title}</title>\n",
    "            </head>\n",
    "            <body>\n",
    "                <style type = \"text/css\">\n",
    "                    body {{font-family: Courier; font-size: 12px;width: 88%; margin: 6%}}\n",
    "                    .wrapper {{width:fit-content;margin:9 auto; max-width: 900px}}\n",
    "                    .title {{font-size: 32px}}\n",
    "                    .abstract {{text-align:justify}}\n",
    "                    .discussion {{margin-top: 32px}}\n",
    "                    .reply {{display: flex; margin: 32px 0}}\n",
    "                    .author {{text-align: center;padding: 0 32px}}\n",
    "                    .author img {{width: 96px; border-radius: 8px}}\n",
    "                    .name {{font-weight:bold}}\n",
    "                    .role {{}}\n",
    "                    .time {{font-size: 10px}}\n",
    "                    .comment {{border:solid 2px #ddd; padding: 12px; border-radius: 12px; height: fit-content}}\n",
    "                    .review {{font-weight:bold}}\n",
    "                </style>\n",
    "                <div class = \"wrapper\">\n",
    "                    <div class = \"review\">automatically generated review for research paper</div>\n",
    "                    <div class = \"title\">{self.paper.title}</div>\n",
    "                    <div class = \"abstract\">{self.paper.abstract}</div>\n",
    "                    <div class = \"discussion\">{htmlres}</div>\n",
    "                </div>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        report = f'data/results/{paper.filename}.html'\n",
    "        open(report, 'w').write(html)\n",
    "        \n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3631a1c5-d373-4158-ba3e-45d9f1417b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style = \"margin-top:18px\"><a href = \"data/results/1706.03762v7.html\">Review for Attention Is All You Need</a></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = Report(editor, paper)\n",
    "report.json()\n",
    "\n",
    "display(HTML(f'<p style = \"margin-top:18px\"><a href = \"{report.html()}\">Review for {paper.title}</a></p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f4f2bb-b9da-4c80-b951-2d2c88ea6157",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "    [1] R. M. Blank, “The Effects of Double-Blind versus Single-Blind Reviewing: Experimental Evidence from The American Economic Review,” The American Economic Review, vol. 81, no. 5, pp. 1041–1067, 1991.\n",
    "    \n",
    "    [2] A. E. Budden, T. Tregenza, L. W. Aarssen, J. Koricheva, R. Leimu, and C. J. Lortie, “Double-blind review favours increased representation of female authors,” Trends in Ecology & Evolution, vol. 23, no. 1, pp. 4–6, Jan. 2008, doi: 10.1016/j.tree.2007.07.008.\n",
    "\n",
    "    [3] T. J. Webb, B. O’Hara, and R. P. Freckleton, “Does double-blind review benefit female authors?,” Trends in Ecology & Evolution, vol. 23, no. 7, pp. 351–353, Jul. 2008, doi: 10.1016/j.tree.2008.03.003.\n",
    "    \n",
    "    [4] E. S. Darling, “Use of double-blind peer review to increase author diversity,” Conservation Biology, vol. 29, no. 1, pp. 297–299, 2015.\n",
    "    \n",
    "    [5] K. Okike, K. T. Hug, M. S. Kocher, and S. S. Leopold, “Single-blind vs Double-blind Peer Review in the Setting of Author Prestige,” JAMA, vol. 316, no. 12, pp. 1315–1316, Sep. 2016, doi: 10.1001/jama.2016.11014.\n",
    "    \n",
    "    [6] A. Tomkins, M. Zhang, and W. D. Heavlin, “Reviewer bias in single- versus double-blind peer review,” Proceedings of the National Academy of Sciences, vol. 114, no. 48, pp. 12708–12713, Nov. 2017, doi: 10.1073/pnas.1707323114.\n",
    "    \n",
    "    [7] A. R. Kern-Goldberger, R. James, V. Berghella, and E. S. Miller, “The impact of double-blind peer review on gender bias in scientific publishing: a systematic review,” American Journal of Obstetrics and Gynecology, vol. 227, no. 1, pp. 43-50.e4, Jul. 2022, doi: 10.1016/j.ajog.2022.01.030.\n",
    "    \n",
    "    [8] M. A. Ucci, F. D’Antonio, and V. Berghella, “Double- vs single-blind peer review effect on acceptance rates: a systematic review and meta-analysis of randomized trials,” American Journal of Obstetrics & Gynecology MFM, vol. 4, no. 4, p. 100645, Jul. 2022, doi: 10.1016/j.ajogmf.2022.100645.\n",
    "    \n",
    "    [9] W. Yuan, P. Liu, and G. Neubig, “Can We Automate Scientific Reviewing?,” jair, vol. 75, pp. 171–212, Sep. 2022, doi: 10.1613/jair.1.12862.\n",
    "    \n",
    "    [10] A. Checco, L. Bracciale, P. Loreti, S. Pinfield, and G. Bianchi, “AI-assisted peer review,” Humanit Soc Sci Commun, vol. 8, no. 1, Art. no. 1, Jan. 2021, doi: 10.1057/s41599-020-00703-8.\n",
    "    \n",
    "    [11] A. Saad et al., “Exploring the potential of ChatGPT in the peer review process: An observational study,” Diabetes & Metabolic Syndrome: Clinical Research & Reviews, vol. 18, no. 2, p. 102946, Feb. 2024, doi: 10.1016/j.dsx.2024.102946.\n",
    "    \n",
    "    [12] Y. Jin et al., “AgentReview: Exploring Peer Review Dynamics with LLM Agents,” Oct. 13, 2024, arXiv: arXiv:2406.12708. doi: 10.48550/arXiv.2406.12708.\n",
    "    \n",
    "    [13] M. Thelwall and A. Yaghi, “Evaluating the Predictive Capacity of ChatGPT for Academic Peer Review Outcomes Across Multiple Platforms,” Nov. 14, 2024, arXiv: arXiv:2411.09763. doi: 10.48550/arXiv.2411.09763.\n",
    "    \n",
    "    [14] K. Cheng, Z. Sun, X. Liu, H. Wu, and C. Li, “Generative artificial intelligence is infiltrating peer review process,” Crit Care, vol. 28, no. 1, p. 149, May 2024, doi: 10.1186/s13054-024-04933-z.\n",
    "    \n",
    "    [15] M. Hosseini and S. P. J. M. Horbach, “Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other large language models in scholarly peer review,” Res Integr Peer Rev, vol. 8, no. 1, p. 4, May 2023, doi: 10.1186/s41073-023-00133-5.\n",
    "    \n",
    "    [16] M. D’Arcy, T. Hope, L. Birnbaum, and D. Downey, “MARG: Multi-Agent Review Generation for Scientific Papers,” Jan. 08, 2024, arXiv: arXiv:2401.04259. doi: 10.48550/arXiv.2401.04259.\n",
    "\n",
    "    [17] A. F. Rasheed, M. Zarkoosh, S. F. Abbas, and S. S. Al-Azzawi, “TaskComplexity: A Dataset for Task Complexity Classification with In-Context Learning, FLAN-T5 and GPT-4o Benchmarks,” Sep. 30, 2024, arXiv: arXiv:2409.20189. doi: 10.48550/arXiv.2409.20189.\n",
    "\n",
    "    [18]  A. Behrouz, P. Zhong, and V. Mirrokni, “Titans: Learning to Memorize at Test Time,” Dec. 31, 2024, arXiv: arXiv:2501.00663. doi: 10.48550/arXiv.2501.00663.\n",
    "\n",
    "    [19] J. Cao, “A Study on Deploying Large Language Models as Agents,” Thesis, Massachusetts Institute of Technology, 2024. Accessed: Jan. 22, 2025. [Online]. Available: https://dspace.mit.edu/handle/1721.1/157177"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
